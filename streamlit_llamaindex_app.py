# streamlit_llamaindex_app.py
"""
Analyse d'Appels d'Offres - Architecture Multi-Agents
-----------------------------------------------------
‚ñ∂Ô∏è  Ce script fournit :
   ‚Ä¢ Upload multi-fichiers (PDF, DOCX, TXT, XLSX‚Ä¶)
   ‚Ä¢ Classification automatique des documents
   ‚Ä¢ Analyse sp√©cialis√©e par type de document
   ‚Ä¢ Agents sp√©cialis√©s (R√®glement, CCTP, CCAP, DPGF)
   ‚Ä¢ Chat contextuel avec m√©moire technique

‚öôÔ∏è  D√©pendances :
   pip install -r requirements.txt

Lancez :
   streamlit run streamlit_llamaindex_app.py
"""

from __future__ import annotations
import os, uuid, tempfile, shutil, time, json, traceback, re
from pathlib import Path
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum

import streamlit as st
from dotenv import load_dotenv
import pandas as pd
try:
    import pdfplumber
except ImportError:
    pdfplumber = None
    st.warning("‚ö†Ô∏è  pdfplumber non install√©. L'extraction PDF sera limit√©e.")

# ‚ï≠‚îÄ LlamaIndex ‚Äì Core + Agents ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
from llama_index.core import (
    SimpleDirectoryReader,
    VectorStoreIndex,
    StorageContext,
    ServiceContext,
    Settings,
    Document,
)
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.vector_stores.chroma import ChromaVectorStore  
from llama_index.core.response_synthesizers import get_response_synthesizer
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core.callbacks import CallbackManager, TokenCountingHandler
# from llama_index.agent import ReActAgent  # Comment√© pour l'instant
# from llama_index.tools import QueryEngineTool  # Comment√© pour l'instant
# from llama_index.core.query_engine import SubQuestionQueryEngine  # Comment√© pour l'instant
# from llama_index.core.retrievers import VectorIndexRetriever  # Comment√© pour l'instant

# ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ

# --------------------------- Configuration Environnement ---------------------------

# Chargement des variables d'environnement
load_dotenv()

# Configuration OpenAI
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    st.warning("‚ö†Ô∏è  OPENAI_API_KEY manquant dans l'env (dotenv ou shell)")
    st.info("üí° Cr√©ez un fichier .env avec : OPENAI_API_KEY=your_key_here")

# Configuration des mod√®les
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
TEMPERATURE = float(os.getenv("TEMPERATURE", "0.3"))

# Configuration de l'application
DEBUG = os.getenv("DEBUG", "True").lower() == "true"
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")

# Configuration des limites
MAX_TOKENS_PER_REQUEST = int(os.getenv("MAX_TOKENS_PER_REQUEST", "4000"))
AUTO_PURGE_DAYS = int(os.getenv("AUTO_PURGE_DAYS", "3"))

# --------------------------- Types et Enums ---------------------------

class DocumentType(Enum):
    REGLEMENT = "R√®glement de consultation"
    CCTP = "Cahier des Clauses Techniques Particuli√®res"
    CCAP = "Cahier des Clauses Administratives Particuli√®res"
    DPGF = "D√©tail Quantitatif et Estimatif"
    PLANS = "Plans et notes historiques"
    AUTRE = "Autre document"

@dataclass
class DocumentInfo:
    name: str
    type: DocumentType
    content: str
    metadata: Dict[str, Any]
    analysis: Dict[str, Any] = None  # type: ignore

# --------------------------- Config ---------------------------
DATA_DIR = Path("./uploads")
VECTOR_DIR = Path("./storage")
DATA_DIR.mkdir(exist_ok=True)
VECTOR_DIR.mkdir(exist_ok=True)

# Limite m√©moire : auto-purge indices anciens
purge_seconds = AUTO_PURGE_DAYS * 24 * 3600
for d in VECTOR_DIR.iterdir():
    if d.is_dir() and (time.time() - d.stat().st_mtime) > purge_seconds:
        shutil.rmtree(d, ignore_errors=True)

# ---------------------- Classification des Documents --------------------

def classify_document(filename: str, content: str = "") -> DocumentType:
    """Classe automatiquement un document selon son nom et contenu."""
    
    # Classification par nom de fichier
    filename_lower = filename.lower()
    
    # R√®gles de classification
    if any(keyword in filename_lower for keyword in ["reglement", "consultation", "rc"]):
        return DocumentType.REGLEMENT
    elif any(keyword in filename_lower for keyword in ["cctp", "technique", "techniques"]):
        return DocumentType.CCTP
    elif any(keyword in filename_lower for keyword in ["ccap", "administratif", "administratives"]):
        return DocumentType.CCAP
    elif any(keyword in filename_lower for keyword in ["dpgf", "quantitatif", "estimatif", "quantite"]):
        return DocumentType.DPGF
    elif any(keyword in filename_lower for keyword in ["plan", "plans", "historique", "note"]):
        return DocumentType.PLANS
    
    # Si pas de classification par nom, analyser le contenu
    if content:
        content_lower = content.lower()
        
        # Analyse s√©mantique basique
        if any(term in content_lower for term in ["crit√®res de s√©lection", "modalit√©s", "attribution"]):
            return DocumentType.REGLEMENT
        elif any(term in content_lower for term in ["exigences techniques", "mat√©riaux", "m√©thodes"]):
            return DocumentType.CCTP
        elif any(term in content_lower for term in ["p√©nalit√©s", "d√©lais", "obligations administratives"]):
            return DocumentType.CCAP
        elif any(term in content_lower for term in ["quantit√©s", "estimations", "co√ªts unitaires"]):
            return DocumentType.DPGF
    
    return DocumentType.AUTRE

# ---------------------- Extraction de Contenu --------------------

def extract_pdf_content(file_path: Path) -> str:
    """Extrait le contenu texte d'un PDF avec pdfplumber."""
    if pdfplumber is None:
        st.error("pdfplumber non install√©. Impossible d'extraire le contenu PDF.")
        return ""
    
    try:
        with pdfplumber.open(file_path) as pdf:
            text = ""
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    except Exception as e:
        st.error(f"Erreur extraction PDF {file_path.name}: {e}")
        return ""

def extract_excel_content(file_path: Path) -> str:
    """Extrait le contenu d'un fichier Excel."""
    try:
        df = pd.read_excel(file_path)
        return df.to_string()
    except Exception as e:
        st.error(f"Erreur extraction Excel {file_path.name}: {e}")
        return ""

def extract_document_content(file_path: Path) -> str:
    """Extrait le contenu selon le type de fichier."""
    if file_path.suffix.lower() == '.pdf':
        return extract_pdf_content(file_path)
    elif file_path.suffix.lower() in ['.xlsx', '.xls']:
        return extract_excel_content(file_path)
    else:
        # Pour les autres types, lecture simple
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except:
            return ""

# ---------------------- Agents Sp√©cialis√©s --------------------

class DocumentAnalyzer:
    """Classe pour analyser les documents avec des agents sp√©cialis√©s avanc√©s."""
    
    def __init__(self):
        self.llm = OpenAI(model=LLM_MODEL, temperature=TEMPERATURE)
        self.embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)
        
        # Base de connaissances des chantiers pr√©c√©dents (simul√©e)
        self.previous_projects = {
            "restauration_facade": {
                "type": "Restauration fa√ßade monument historique",
                "contraintes": ["√©chafaudage", "protection vitraux", "pierre de taille"],
                "duree": "6 mois",
                "montant": "30000-50000‚Ç¨"
            },
            "renovation_interieur": {
                "type": "R√©novation int√©rieur √©glise",
                "contraintes": ["conservation peintures", "acc√®s limit√©", "√©clairage"],
                "duree": "4 mois",
                "montant": "20000-35000‚Ç¨"
            },
            "consolidation_structure": {
                "type": "Consolidation structure",
                "contraintes": ["renforcement", "√©taiement", "s√©curit√©"],
                "duree": "8 mois",
                "montant": "50000-80000‚Ç¨"
            }
        }
        
    def analyze_reglement(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du r√®glement de consultation."""
        prompt = f"""
        Analyse ce r√®glement de consultation et extrait les informations cl√©s de mani√®re d√©taill√©e :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re exhaustive :
        
        1. CRIT√àRES DE S√âLECTION ET D'ATTRIBUTION
           - Crit√®res techniques (pourcentage, poids)
           - Crit√®res financiers (pourcentage, poids)
           - Crit√®res d'exp√©rience (pourcentage, poids)
           - Crit√®res de capacit√© (pourcentage, poids)
           - M√©thode de notation et de classement
        
        2. D√âLAIS IMPORTANTS
           - Date limite de d√©p√¥t des offres
           - Date d'ouverture des plis
           - Dur√©e du chantier (d√©but/fin)
           - D√©lais de r√©ception provisoire/d√©finitive
           - P√©riodes critiques √† identifier
        
        3. MODALIT√âS ADMINISTRATIVES
           - Garanties requises (pourcentage, montant)
           - Assurances obligatoires (types, montants)
           - Cautionnement (pourcentage, montant)
           - Conditions de paiement
           - Modalit√©s de r√©ception
        
        4. CONDITIONS PARTICULI√àRES
           - Contraintes sp√©cifiques au site
           - Conditions d'acc√®s au chantier
           - Contraintes environnementales
           - Contraintes de voisinage
           - Conditions m√©t√©orologiques
        
        5. DOCUMENTS REQUIS
           - Attestations obligatoires
           - Justificatifs d'exp√©rience
           - Plans et documents techniques
           - M√©moire technique (contenu requis)
           - Planning d√©taill√©
        
        6. RISQUES IDENTIFI√âS
           - Risques techniques majeurs
           - Risques administratifs
           - Risques financiers
           - Risques de d√©lais
           - P√©nalit√©s applicables
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"analyse": response.text}
    
    def analyze_cctp(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du CCTP (Cahier des Clauses Techniques Particuli√®res)."""
        prompt = f"""
        Analyse ce CCTP et extrait les exigences techniques de mani√®re exhaustive :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re d√©taill√©e :
        
        1. EXIGENCES TECHNIQUES PR√âCISES
           - Sp√©cifications techniques d√©taill√©es
           - Normes et r√©f√©rences applicables
           - Classes de r√©sistance et caract√©ristiques
           - Contr√¥les et essais requis
           - Tol√©rances et marges acceptables
        
        2. MAT√âRIAUX ET M√âTHODES REQUIS
           - Types de mat√©riaux sp√©cifi√©s
           - Origines et qualit√©s requises
           - M√©thodes de mise en ≈ìuvre
           - √âquipements et outils n√©cessaires
           - Conditions de stockage et transport
        
        3. CONTRAINTES SP√âCIFIQUES
           - Contraintes de mise en ≈ìuvre
           - Contraintes de s√©curit√©
           - Contraintes de qualit√©
           - Contraintes de d√©lais
           - Contraintes d'environnement
        
        4. NORMES ET R√âF√âRENCES TECHNIQUES
           - Normes fran√ßaises (NF)
           - Normes europ√©ennes (EN)
           - DTU et guides techniques
           - Cahiers des charges types
           - R√©f√©rentiels sp√©cifiques
        
        5. CONTRAINTES ENVIRONNEMENTALES
           - Gestion des d√©chets
           - Protection de la biodiversit√©
           - Limitation des nuisances
           - √âconomie circulaire
           - D√©veloppement durable
        
        6. SIMILITUDES AVEC CHANTIERS PR√âC√âDENTS
           - Types d'ouvrages similaires
           - Techniques communes
           - Mat√©riaux identiques
           - Contraintes comparables
           - Exp√©riences r√©utilisables
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            result = json.loads(response.text)
            # Ajouter la d√©tection de similitudes
            result["similitudes_chantiers"] = self._detect_similar_projects(content)
            return result
        except:
            return {"analyse": response.text}
    
    def analyze_ccap(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du CCAP (Cahier des Clauses Administratives Particuli√®res)."""
        prompt = f"""
        Analyse ce CCAP et extrait les contraintes administratives de mani√®re exhaustive :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re d√©taill√©e :
        
        1. RISQUES ET P√âNALIT√âS
           - P√©nalit√©s de retard (montant, calcul)
           - P√©nalit√©s de non-conformit√©
           - R√©siliation pour faute
           - Indemnit√©s forfaitaires
           - Garanties de bonne fin
        
        2. D√âLAIS CRITIQUES
           - Dates de d√©but et fin
           - Jalons interm√©diaires
           - R√©ceptions provisoire/d√©finitive
           - D√©lais de paiement
           - D√©lais de garantie
        
        3. OBLIGATIONS ADMINISTRATIVES
           - Plan de pr√©vention
           - Registre de s√©curit√©
           - D√©clarations d'accident
           - Visites de chantier
           - R√©unions de coordination
        
        4. CONDITIONS DE PAIEMENT
           - Acomptes et modalit√©s
           - Retenues de garantie
           - D√©lais de paiement
           - Justificatifs requis
           - Conditions de d√©blocage
        
        5. GARANTIES ET ASSURANCES
           - Garantie de parfait ach√®vement
           - Garantie biennale
           - Assurance d√©cennale
           - Responsabilit√© civile
           - Montants et dur√©es
        
        6. CONTRAINTES LOGISTIQUES
           - Acc√®s au chantier
           - Stationnement et livraisons
           - Horaires de travail
           - Nuisances sonores
           - Gestion des flux
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"analyse": response.text}
    
    def analyze_dpgf(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du DPGF (D√©tail Quantitatif et Estimatif)."""
        prompt = f"""
        Analyse ce DPGF et extrait les informations quantitatives de mani√®re exhaustive :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re d√©taill√©e :
        
        1. QUANTIT√âS ET ESTIMATIONS
           - D√©tail quantitatif par lot
           - Unit√©s de mesure
           - Quantit√©s estim√©es
           - Marges d'incertitude
           - R√©partition g√©ographique
        
        2. D√âTAIL DES PRESTATIONS
           - Description technique d√©taill√©e
           - M√©thodes de r√©alisation
           - Mat√©riaux et √©quipements
           - Main d'≈ìuvre requise
           - Contr√¥les et essais
        
        3. CO√õTS UNITAIRES
           - Prix unitaires HT
           - Co√ªts de main d'≈ìuvre
           - Co√ªts de mat√©riaux
           - Co√ªts d'√©quipements
           - Frais g√©n√©raux
        
        4. R√âPARTITION DES LOTS
           - D√©coupage en lots
           - Montants par lot
           - Interd√©pendances
           - Planning par lot
           - Risques par lot
        
        5. PLANNING PR√âVISIONNEL
           - Phases de r√©alisation
           - Dur√©es par phase
           - Encha√Ænement des t√¢ches
           - Ressources n√©cessaires
           - Points critiques
        
        6. ANALYSE √âCONOMIQUE
           - R√©partition des co√ªts
           - Postes les plus co√ªteux
           - Optimisations possibles
           - Risques financiers
           - Marges b√©n√©ficiaires
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"analyse": response.text}
    
    def _detect_similar_projects(self, content: str) -> Dict[str, Any]:
        """D√©tecte les similitudes avec des chantiers pr√©c√©dents."""
        prompt = f"""
        Analyse ce contenu et identifie les similitudes avec des types de chantiers connus :
        
        CONTENU :
        {content[:2000]}
        
        Types de chantiers de r√©f√©rence :
        - restauration_facade : Restauration fa√ßade monument historique
        - renovation_interieur : R√©novation int√©rieur √©glise  
        - consolidation_structure : Consolidation structure
        
        Identifie :
        1. Type de chantier le plus similaire
        2. Contraintes communes
        3. Techniques similaires
        4. Mat√©riaux identiques
        5. Risques comparables
        
        R√©ponds au format JSON.
        """
        
        try:
            response = self.llm.complete(prompt)
            return json.loads(response.text)
        except:
            return {"similitudes": "Analyse non disponible"}
    
    def analyze_environmental_constraints(self, content: str) -> Dict[str, Any]:
        """Analyse sp√©cialis√©e des contraintes environnementales."""
        prompt = f"""
        Analyse ce document et extrait toutes les contraintes environnementales :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Identifie et structure :
        
        1. GESTION DES NUISANCES
           - Nuisances sonores (horaires, niveaux)
           - Nuisances visuelles (√©chafaudages, b√¢ches)
           - Nuisances olfactives (produits, d√©chets)
           - Vibrations (√©quipements, m√©thodes)
        
        2. PROTECTION DE LA BIODIVERSIT√â
           - Esp√®ces prot√©g√©es pr√©sentes
           - P√©riodes de reproduction
           - Nichoirs et habitats
           - Mesures de protection
           - Suivi √©cologique
        
        3. GESTION DES D√âCHETS
           - Types de d√©chets g√©n√©r√©s
           - Quantit√©s estim√©es
           - Tri et recyclage
           - √âvacuation et traitement
           - Tra√ßabilit√©
        
        4. √âCONOMIE CIRCULAIRE
           - R√©utilisation de mat√©riaux
           - Recyclage sur site
           - Approvisionnement local
           - R√©duction des d√©chets
           - Optimisation des ressources
        
        5. D√âVELOPPEMENT DURABLE
           - √ânergies renouvelables
           - Mat√©riaux √©cologiques
           - Transport propre
           - Bilan carbone
           - Certifications
        
        R√©ponds au format JSON structur√©.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"contraintes_environnementales": response.text}
    
    def analyze_logistical_constraints(self, content: str) -> Dict[str, Any]:
        """Analyse sp√©cialis√©e des contraintes logistiques."""
        prompt = f"""
        Analyse ce document et extrait toutes les contraintes logistiques :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Identifie et structure :
        
        1. ACC√àS AU CHANTIER
           - Voies d'acc√®s disponibles
           - Restrictions de circulation
           - Largeurs et hauteurs
           - Capacit√©s de charge
           - Permis de circulation
        
        2. STATIONNEMENT ET LIVRAISONS
           - Zones de stationnement
           - Horaires de livraison
           - Espaces de man≈ìuvre
           - Gestion des flux
           - Coordination logistique
        
        3. HORAIRES DE TRAVAIL
           - Plages horaires autoris√©es
           - Jours de travail
           - Pauses obligatoires
           - Travail de nuit
           - Dimanches et f√™tes
        
        4. GESTION DES FLUX
           - Circulation des engins
           - Flux de mat√©riaux
           - √âvacuation des d√©chets
           - Acc√®s des intervenants
           - S√©curisation des zones
        
        5. CONTRAINTES DE VOISINAGE
           - Proximit√© d'habitations
           - √âtablissements sensibles
           - Commerces et activit√©s
           - Mesures d'apaisement
           - Communication
        
        R√©ponds au format JSON structur√©.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"contraintes_logistiques": response.text}

class TechnicalMemoryGenerator:
    """G√©n√©rateur de m√©moires techniques bas√© sur les analyses de documents."""
    
    def __init__(self):
        self.llm = OpenAI(model=LLM_MODEL, temperature=0.4)  # Temp√©rature l√©g√®rement plus √©lev√©e pour la cr√©ativit√©
        
        # Templates de m√©moires techniques par type de chantier
        self.memory_templates = {
            "restauration_facade": {
                "sections": [
                    "Pr√©sentation de l'entreprise",
                    "Compr√©hension du projet",
                    "M√©thodologie de travail",
                    "Organisation du chantier",
                    "Gestion des contraintes",
                    "Planning d√©taill√©",
                    "S√©curit√© et environnement",
                    "Garanties et assurances"
                ]
            },
            "renovation_interieur": {
                "sections": [
                    "Pr√©sentation de l'entreprise",
                    "Analyse technique du projet",
                    "M√©thodes de conservation",
                    "Organisation et planning",
                    "Gestion des contraintes d'acc√®s",
                    "Protection des √©l√©ments existants",
                    "Contr√¥le qualit√©",
                    "Garanties"
                ]
            },
            "consolidation_structure": {
                "sections": [
                    "Pr√©sentation de l'entreprise",
                    "Diagnostic structurel",
                    "Solutions techniques propos√©es",
                    "M√©thodes de renforcement",
                    "Organisation du chantier",
                    "S√©curit√© et √©taiement",
                    "Contr√¥les et essais",
                    "Garanties d√©cennales"
                ]
            }
        }
    
    def generate_technical_memory(self, project_analysis: Dict[str, Any], company_info: Dict[str, Any] = {}) -> Dict[str, Any]:
        """G√©n√®re une m√©moire technique compl√®te bas√©e sur l'analyse du projet."""
        
        # D√©terminer le type de chantier
        project_type = self._identify_project_type(project_analysis)
        
        # Informations de l'entreprise par d√©faut
        if not company_info:
            company_info = {
                "nom": "Entreprise de Restauration du Patrimoine",
                "siret": "12345678901234",
                "adresse": "123 Rue du Patrimoine, 75001 Paris",
                "telephone": "01 23 45 67 89",
                "email": "contact@restauration-patrimoine.fr",
                "experience": "15 ans d'exp√©rience en restauration de monuments historiques",
                "certifications": ["Qualibat 1511", "Monuments Historiques", "ISO 9001"]
            }
        
        # G√©n√©rer chaque section de la m√©moire
        memory_sections = {}
        
        # 1. Pr√©sentation de l'entreprise
        memory_sections["presentation_entreprise"] = self._generate_company_presentation(company_info)
        
        # 2. Compr√©hension du projet
        memory_sections["comprehension_projet"] = self._generate_project_understanding(project_analysis)
        
        # 3. M√©thodologie de travail
        memory_sections["methodologie"] = self._generate_methodology(project_analysis, project_type)
        
        # 4. Organisation du chantier
        memory_sections["organisation_chantier"] = self._generate_site_organization(project_analysis)
        
        # 5. Gestion des contraintes
        memory_sections["gestion_contraintes"] = self._generate_constraints_management(project_analysis)
        
        # 6. Planning d√©taill√©
        memory_sections["planning"] = self._generate_detailed_planning(project_analysis)
        
        # 7. S√©curit√© et environnement
        memory_sections["securite_environnement"] = self._generate_safety_environment(project_analysis)
        
        # 8. Garanties et assurances
        memory_sections["garanties"] = self._generate_guarantees(company_info)
        
        # 9. Annexes techniques
        memory_sections["annexes"] = self._generate_technical_annexes(project_analysis)
        
        return {
            "type_projet": project_type,
            "sections": memory_sections,
            "metadata": {
                "date_generation": time.strftime("%Y-%m-%d %H:%M:%S"),
                "version": "1.0",
                "nombre_sections": len(memory_sections)
            }
        }
    
    def _identify_project_type(self, project_analysis: Dict[str, Any]) -> str:
        """Identifie le type de projet bas√© sur l'analyse."""
        content = str(project_analysis).lower()
        
        if any(term in content for term in ["fa√ßade", "pierre", "√©chafaudage", "vitraux"]):
            return "restauration_facade"
        elif any(term in content for term in ["int√©rieur", "peinture", "conservation", "acc√®s limit√©"]):
            return "renovation_interieur"
        elif any(term in content for term in ["structure", "consolidation", "renforcement", "√©taiement"]):
            return "consolidation_structure"
        else:
            return "restauration_facade"  # Par d√©faut
    
    def _generate_company_presentation(self, company_info: Dict[str, Any]) -> str:
        """G√©n√®re la section pr√©sentation de l'entreprise."""
        prompt = f"""
        G√©n√®re une pr√©sentation professionnelle de l'entreprise pour une m√©moire technique :
        
        INFORMATIONS ENTREPRISE :
        {json.dumps(company_info, indent=2, ensure_ascii=False)}
        
        Cr√©e une pr√©sentation structur√©e incluant :
        - Pr√©sentation g√©n√©rale de l'entreprise
        - Exp√©rience et r√©f√©rences
        - Certifications et qualifications
        - √âquipe et comp√©tences
        - Valeurs et engagement qualit√©
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_project_understanding(self, project_analysis: Dict[str, Any]) -> str:
        """G√©n√®re la section compr√©hension du projet."""
        prompt = f"""
        G√©n√®re une section "Compr√©hension du projet" pour une m√©moire technique :
        
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e une analyse structur√©e incluant :
        - Contexte et enjeux du projet
        - Contraintes identifi√©es
        - Objectifs techniques
        - Risques principaux
        - Opportunit√©s d'optimisation
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_methodology(self, project_analysis: Dict[str, Any], project_type: str) -> str:
        """G√©n√®re la section m√©thodologie de travail."""
        prompt = f"""
        G√©n√®re une section "M√©thodologie de travail" pour une m√©moire technique :
        
        TYPE DE PROJET : {project_type}
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e une m√©thodologie structur√©e incluant :
        - Approche g√©n√©rale
        - Phases de travail d√©taill√©es
        - Techniques et mat√©riaux
        - Contr√¥les qualit√©
        - Gestion des impr√©vus
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_site_organization(self, project_analysis: Dict[str, Any]) -> str:
        """G√©n√®re la section organisation du chantier."""
        prompt = f"""
        G√©n√®re une section "Organisation du chantier" pour une m√©moire technique :
        
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e une organisation structur√©e incluant :
        - √âquipe et responsabilit√©s
        - Logistique et mat√©riel
        - Coordination et communication
        - Gestion des flux
        - S√©curisation du site
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_constraints_management(self, project_analysis: Dict[str, Any]) -> str:
        """G√©n√®re la section gestion des contraintes."""
        prompt = f"""
        G√©n√®re une section "Gestion des contraintes" pour une m√©moire technique :
        
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e une gestion des contraintes structur√©e incluant :
        - Contraintes techniques identifi√©es
        - Contraintes environnementales
        - Contraintes logistiques
        - Contraintes administratives
        - Solutions et mesures d'adaptation
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_detailed_planning(self, project_analysis: Dict[str, Any]) -> str:
        """G√©n√®re la section planning d√©taill√©."""
        prompt = f"""
        G√©n√®re une section "Planning d√©taill√©" pour une m√©moire technique :
        
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e un planning structur√© incluant :
        - Phases principales du chantier
        - Jalons et livrables
        - Ressources par phase
        - D√©lais critiques
        - Marges de s√©curit√©
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_safety_environment(self, project_analysis: Dict[str, Any]) -> str:
        """G√©n√®re la section s√©curit√© et environnement."""
        prompt = f"""
        G√©n√®re une section "S√©curit√© et environnement" pour une m√©moire technique :
        
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e une section structur√©e incluant :
        - Mesures de s√©curit√©
        - Protection de l'environnement
        - Gestion des d√©chets
        - Pr√©vention des risques
        - Formation et sensibilisation
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_guarantees(self, company_info: Dict[str, Any]) -> str:
        """G√©n√®re la section garanties et assurances."""
        prompt = f"""
        G√©n√®re une section "Garanties et assurances" pour une m√©moire technique :
        
        INFORMATIONS ENTREPRISE :
        {json.dumps(company_info, indent=2, ensure_ascii=False)}
        
        Cr√©e une section structur√©e incluant :
        - Garanties contractuelles
        - Assurances obligatoires
        - Garantie de parfait ach√®vement
        - Garantie d√©cennale
        - Engagements qualit√©
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def _generate_technical_annexes(self, project_analysis: Dict[str, Any]) -> str:
        """G√©n√®re les annexes techniques."""
        prompt = f"""
        G√©n√®re des "Annexes techniques" pour une m√©moire technique :
        
        ANALYSE DU PROJET :
        {json.dumps(project_analysis, indent=2, ensure_ascii=False)}
        
        Cr√©e des annexes structur√©es incluant :
        - R√©f√©rences techniques
        - Normes applicables
        - Sch√©mas et plans
        - Fiches techniques
        - Certifications
        
        Format : Texte structur√© avec paragraphes clairs.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def generate_memory_summary(self, technical_memory: Dict[str, Any]) -> str:
        """G√©n√®re un r√©sum√© ex√©cutif de la m√©moire technique."""
        prompt = f"""
        G√©n√®re un r√©sum√© ex√©cutif de cette m√©moire technique :
        
        M√âMOIRE TECHNIQUE :
        {json.dumps(technical_memory, indent=2, ensure_ascii=False)}
        
        Cr√©e un r√©sum√© structur√© incluant :
        - Points cl√©s du projet
        - Approche propos√©e
        - Avantages concurrentiels
        - Engagements
        - Conclusion
        
        Format : Texte concis et professionnel.
        """
        
        response = self.llm.complete(prompt)
        return response.text
    
    def export_memory_to_markdown(self, technical_memory: Dict[str, Any]) -> str:
        """Exporte la m√©moire technique au format Markdown."""
        markdown_content = f"""# M√©moire Technique - {technical_memory.get('type_projet', 'Projet de restauration').replace('_', ' ').title()}

*G√©n√©r√©e le {technical_memory.get('metadata', {}).get('date_generation', 'Date inconnue')}*

---

## 1. Pr√©sentation de l'entreprise

{technical_memory.get('sections', {}).get('presentation_entreprise', 'Section non disponible')}

---

## 2. Compr√©hension du projet

{technical_memory.get('sections', {}).get('comprehension_projet', 'Section non disponible')}

---

## 3. M√©thodologie de travail

{technical_memory.get('sections', {}).get('methodologie', 'Section non disponible')}

---

## 4. Organisation du chantier

{technical_memory.get('sections', {}).get('organisation_chantier', 'Section non disponible')}

---

## 5. Gestion des contraintes

{technical_memory.get('sections', {}).get('gestion_contraintes', 'Section non disponible')}

---

## 6. Planning d√©taill√©

{technical_memory.get('sections', {}).get('planning', 'Section non disponible')}

---

## 7. S√©curit√© et environnement

{technical_memory.get('sections', {}).get('securite_environnement', 'Section non disponible')}

---

## 8. Garanties et assurances

{technical_memory.get('sections', {}).get('garanties', 'Section non disponible')}

---

## 9. Annexes techniques

{technical_memory.get('sections', {}).get('annexes', 'Section non disponible')}

---

*M√©moire technique g√©n√©r√©e automatiquement par l'IA Multi-Agents*
"""
        return markdown_content
    
    def analyze_reglement(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du r√®glement de consultation."""
        prompt = f"""
        Analyse ce r√®glement de consultation et extrait les informations cl√©s de mani√®re d√©taill√©e :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re exhaustive :
        
        1. CRIT√àRES DE S√âLECTION ET D'ATTRIBUTION
           - Crit√®res techniques (pourcentage, poids)
           - Crit√®res financiers (pourcentage, poids)
           - Crit√®res d'exp√©rience (pourcentage, poids)
           - Crit√®res de capacit√© (pourcentage, poids)
           - M√©thode de notation et de classement
        
        2. D√âLAIS IMPORTANTS
           - Date limite de d√©p√¥t des offres
           - Date d'ouverture des plis
           - Dur√©e du chantier (d√©but/fin)
           - D√©lais de r√©ception provisoire/d√©finitive
           - P√©riodes critiques √† identifier
        
        3. MODALIT√âS ADMINISTRATIVES
           - Garanties requises (pourcentage, montant)
           - Assurances obligatoires (types, montants)
           - Cautionnement (pourcentage, montant)
           - Conditions de paiement
           - Modalit√©s de r√©ception
        
        4. CONDITIONS PARTICULI√àRES
           - Contraintes sp√©cifiques au site
           - Conditions d'acc√®s au chantier
           - Contraintes environnementales
           - Contraintes de voisinage
           - Conditions m√©t√©orologiques
        
        5. DOCUMENTS REQUIS
           - Attestations obligatoires
           - Justificatifs d'exp√©rience
           - Plans et documents techniques
           - M√©moire technique (contenu requis)
           - Planning d√©taill√©
        
        6. RISQUES IDENTIFI√âS
           - Risques techniques majeurs
           - Risques administratifs
           - Risques financiers
           - Risques de d√©lais
           - P√©nalit√©s applicables
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"analyse": response.text}
    
    def analyze_cctp(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du CCTP (Cahier des Clauses Techniques Particuli√®res)."""
        prompt = f"""
        Analyse ce CCTP et extrait les exigences techniques de mani√®re exhaustive :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re d√©taill√©e :
        
        1. EXIGENCES TECHNIQUES PR√âCISES
           - Sp√©cifications techniques d√©taill√©es
           - Normes et r√©f√©rences applicables
           - Classes de r√©sistance et caract√©ristiques
           - Contr√¥les et essais requis
           - Tol√©rances et marges acceptables
        
        2. MAT√âRIAUX ET M√âTHODES REQUIS
           - Types de mat√©riaux sp√©cifi√©s
           - Origines et qualit√©s requises
           - M√©thodes de mise en ≈ìuvre
           - √âquipements et outils n√©cessaires
           - Conditions de stockage et transport
        
        3. CONTRAINTES SP√âCIFIQUES
           - Contraintes de mise en ≈ìuvre
           - Contraintes de s√©curit√©
           - Contraintes de qualit√©
           - Contraintes de d√©lais
           - Contraintes d'environnement
        
        4. NORMES ET R√âF√âRENCES TECHNIQUES
           - Normes fran√ßaises (NF)
           - Normes europ√©ennes (EN)
           - DTU et guides techniques
           - Cahiers des charges types
           - R√©f√©rentiels sp√©cifiques
        
        5. CONTRAINTES ENVIRONNEMENTALES
           - Gestion des d√©chets
           - Protection de la biodiversit√©
           - Limitation des nuisances
           - √âconomie circulaire
           - D√©veloppement durable
        
        6. SIMILITUDES AVEC CHANTIERS PR√âC√âDENTS
           - Types d'ouvrages similaires
           - Techniques communes
           - Mat√©riaux identiques
           - Contraintes comparables
           - Exp√©riences r√©utilisables
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            result = json.loads(response.text)
            # Ajouter la d√©tection de similitudes
            result["similitudes_chantiers"] = self._detect_similar_projects(content)
            return result
        except:
            return {"analyse": response.text}
    
    def analyze_ccap(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du CCAP (Cahier des Clauses Administratives Particuli√®res)."""
        prompt = f"""
        Analyse ce CCAP et extrait les contraintes administratives de mani√®re exhaustive :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re d√©taill√©e :
        
        1. RISQUES ET P√âNALIT√âS
           - P√©nalit√©s de retard (montant, calcul)
           - P√©nalit√©s de non-conformit√©
           - R√©siliation pour faute
           - Indemnit√©s forfaitaires
           - Garanties de bonne fin
        
        2. D√âLAIS CRITIQUES
           - Dates de d√©but et fin
           - Jalons interm√©diaires
           - R√©ceptions provisoire/d√©finitive
           - D√©lais de paiement
           - D√©lais de garantie
        
        3. OBLIGATIONS ADMINISTRATIVES
           - Plan de pr√©vention
           - Registre de s√©curit√©
           - D√©clarations d'accident
           - Visites de chantier
           - R√©unions de coordination
        
        4. CONDITIONS DE PAIEMENT
           - Acomptes et modalit√©s
           - Retenues de garantie
           - D√©lais de paiement
           - Justificatifs requis
           - Conditions de d√©blocage
        
        5. GARANTIES ET ASSURANCES
           - Garantie de parfait ach√®vement
           - Garantie biennale
           - Assurance d√©cennale
           - Responsabilit√© civile
           - Montants et dur√©es
        
        6. CONTRAINTES LOGISTIQUES
           - Acc√®s au chantier
           - Stationnement et livraisons
           - Horaires de travail
           - Nuisances sonores
           - Gestion des flux
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"analyse": response.text}
    
    def analyze_dpgf(self, content: str) -> Dict[str, Any]:
        """Analyse avanc√©e du DPGF (D√©tail Quantitatif et Estimatif)."""
        prompt = f"""
        Analyse ce DPGF et extrait les informations quantitatives de mani√®re exhaustive :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Extrais et structure les informations suivantes de mani√®re d√©taill√©e :
        
        1. QUANTIT√âS ET ESTIMATIONS
           - D√©tail quantitatif par lot
           - Unit√©s de mesure
           - Quantit√©s estim√©es
           - Marges d'incertitude
           - R√©partition g√©ographique
        
        2. D√âTAIL DES PRESTATIONS
           - Description technique d√©taill√©e
           - M√©thodes de r√©alisation
           - Mat√©riaux et √©quipements
           - Main d'≈ìuvre requise
           - Contr√¥les et essais
        
        3. CO√õTS UNITAIRES
           - Prix unitaires HT
           - Co√ªts de main d'≈ìuvre
           - Co√ªts de mat√©riaux
           - Co√ªts d'√©quipements
           - Frais g√©n√©raux
        
        4. R√âPARTITION DES LOTS
           - D√©coupage en lots
           - Montants par lot
           - Interd√©pendances
           - Planning par lot
           - Risques par lot
        
        5. PLANNING PR√âVISIONNEL
           - Phases de r√©alisation
           - Dur√©es par phase
           - Encha√Ænement des t√¢ches
           - Ressources n√©cessaires
           - Points critiques
        
        6. ANALYSE √âCONOMIQUE
           - R√©partition des co√ªts
           - Postes les plus co√ªteux
           - Optimisations possibles
           - Risques financiers
           - Marges b√©n√©ficiaires
        
        R√©ponds au format JSON structur√© avec des sous-sections d√©taill√©es.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"analyse": response.text}
    
    def _detect_similar_projects(self, content: str) -> Dict[str, Any]:
        """D√©tecte les similitudes avec des chantiers pr√©c√©dents."""
        prompt = f"""
        Analyse ce contenu et identifie les similitudes avec des types de chantiers connus :
        
        CONTENU :
        {content[:2000]}
        
        Types de chantiers de r√©f√©rence :
        - restauration_facade : Restauration fa√ßade monument historique
        - renovation_interieur : R√©novation int√©rieur √©glise  
        - consolidation_structure : Consolidation structure
        
        Identifie :
        1. Type de chantier le plus similaire
        2. Contraintes communes
        3. Techniques similaires
        4. Mat√©riaux identiques
        5. Risques comparables
        
        R√©ponds au format JSON.
        """
        
        try:
            response = self.llm.complete(prompt)
            return json.loads(response.text)
        except:
            return {"similitudes": "Analyse non disponible"}
    
    def analyze_environmental_constraints(self, content: str) -> Dict[str, Any]:
        """Analyse sp√©cialis√©e des contraintes environnementales."""
        prompt = f"""
        Analyse ce document et extrait toutes les contraintes environnementales :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Identifie et structure :
        
        1. GESTION DES NUISANCES
           - Nuisances sonores (horaires, niveaux)
           - Nuisances visuelles (√©chafaudages, b√¢ches)
           - Nuisances olfactives (produits, d√©chets)
           - Vibrations (√©quipements, m√©thodes)
        
        2. PROTECTION DE LA BIODIVERSIT√â
           - Esp√®ces prot√©g√©es pr√©sentes
           - P√©riodes de reproduction
           - Nichoirs et habitats
           - Mesures de protection
           - Suivi √©cologique
        
        3. GESTION DES D√âCHETS
           - Types de d√©chets g√©n√©r√©s
           - Quantit√©s estim√©es
           - Tri et recyclage
           - √âvacuation et traitement
           - Tra√ßabilit√©
        
        4. √âCONOMIE CIRCULAIRE
           - R√©utilisation de mat√©riaux
           - Recyclage sur site
           - Approvisionnement local
           - R√©duction des d√©chets
           - Optimisation des ressources
        
        5. D√âVELOPPEMENT DURABLE
           - √ânergies renouvelables
           - Mat√©riaux √©cologiques
           - Transport propre
           - Bilan carbone
           - Certifications
        
        R√©ponds au format JSON structur√©.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"contraintes_environnementales": response.text}
    
    def analyze_logistical_constraints(self, content: str) -> Dict[str, Any]:
        """Analyse sp√©cialis√©e des contraintes logistiques."""
        prompt = f"""
        Analyse ce document et extrait toutes les contraintes logistiques :
        
        CONTENU :
        {content[:MAX_TOKENS_PER_REQUEST]}
        
        Identifie et structure :
        
        1. ACC√àS AU CHANTIER
           - Voies d'acc√®s disponibles
           - Restrictions de circulation
           - Largeurs et hauteurs
           - Capacit√©s de charge
           - Permis de circulation
        
        2. STATIONNEMENT ET LIVRAISONS
           - Zones de stationnement
           - Horaires de livraison
           - Espaces de man≈ìuvre
           - Gestion des flux
           - Coordination logistique
        
        3. HORAIRES DE TRAVAIL
           - Plages horaires autoris√©es
           - Jours de travail
           - Pauses obligatoires
           - Travail de nuit
           - Dimanches et f√™tes
        
        4. GESTION DES FLUX
           - Circulation des engins
           - Flux de mat√©riaux
           - √âvacuation des d√©chets
           - Acc√®s des intervenants
           - S√©curisation des zones
        
        5. CONTRAINTES DE VOISINAGE
           - Proximit√© d'habitations
           - √âtablissements sensibles
           - Commerces et activit√©s
           - Mesures d'apaisement
           - Communication
        
        R√©ponds au format JSON structur√©.
        """
        
        response = self.llm.complete(prompt)
        try:
            return json.loads(response.text)
        except:
            return {"contraintes_logistiques": response.text}

# ---------------------- LlamaIndex Helpers --------------------

def build_advanced_index(run_id: str, files) -> tuple:
    """Ingeste les fichiers, les classe, analyse et cr√©e l'index multi-agents."""
    
    # 1. Sauvegarde des fichiers
    tmp_dir = DATA_DIR / run_id
    tmp_dir.mkdir(exist_ok=True)
    
    documents_info = []
    analyzer = DocumentAnalyzer()
    
    # 2. Traitement de chaque fichier
    for f in files:
        dest = tmp_dir / f.name
        with open(dest, "wb") as out:
            out.write(f.getvalue())
        
        # Extraction du contenu
        content = extract_document_content(dest)
        
        # Classification
        doc_type = classify_document(f.name, content)
        
        # Analyse sp√©cialis√©e selon le type
        analysis = {}
        if doc_type == DocumentType.REGLEMENT:
            analysis = analyzer.analyze_reglement(content)
        elif doc_type == DocumentType.CCTP:
            analysis = analyzer.analyze_cctp(content)
            # Ajouter analyse environnementale pour les documents techniques
            env_analysis = analyzer.analyze_environmental_constraints(content)
            analysis["contraintes_environnementales"] = env_analysis
        elif doc_type == DocumentType.CCAP:
            analysis = analyzer.analyze_ccap(content)
            # Ajouter analyse logistique pour les documents administratifs
            log_analysis = analyzer.analyze_logistical_constraints(content)
            analysis["contraintes_logistiques"] = log_analysis
        elif doc_type == DocumentType.DPGF:
            analysis = analyzer.analyze_dpgf(content)
        
        # Analyse environnementale et logistique pour tous les documents
        if not analysis.get("contraintes_environnementales"):
            env_analysis = analyzer.analyze_environmental_constraints(content)
            analysis["contraintes_environnementales"] = env_analysis
        
        if not analysis.get("contraintes_logistiques"):
            log_analysis = analyzer.analyze_logistical_constraints(content)
            analysis["contraintes_logistiques"] = log_analysis
        
        # Cr√©ation du document structur√©
        doc_info = DocumentInfo(
            name=f.name,
            type=doc_type,
            content=content,
            metadata={
                "type": doc_type.value,
                "file_size": len(content)
            }
        )
        # Ajouter l'analyse comme attribut s√©par√©
        doc_info.analysis = analysis
        documents_info.append(doc_info)
    
    # 3. Configuration LlamaIndex
    token_handler = TokenCountingHandler()
    cb_manager = CallbackManager([token_handler])
    
    Settings.llm = OpenAI(model=LLM_MODEL, temperature=TEMPERATURE)
    Settings.embed_model = OpenAIEmbedding(model=EMBEDDING_MODEL)
    Settings.node_parser = SentenceSplitter(chunk_size=2048, chunk_overlap=256)
    Settings.callback_manager = cb_manager
    
    # 4. Cr√©ation des documents LlamaIndex
    llama_docs = []
    analyses_storage = {}  # Stockage s√©par√© des analyses
    
    for doc_info in documents_info:
        # Cr√©er le document LlamaIndex sans les analyses dans les m√©tadonn√©es
        doc = Document(
            text=doc_info.content,
            metadata=doc_info.metadata
        )
        llama_docs.append(doc)
        
        # Stocker l'analyse s√©par√©ment
        if hasattr(doc_info, 'analysis'):
            analyses_storage[doc_info.name] = doc_info.analysis
    
    # 5. Stockage Chroma persistant
    persist_dir = VECTOR_DIR / run_id
    import chromadb
    chroma_client = chromadb.PersistentClient(path=str(persist_dir))
    vector_store = ChromaVectorStore(chroma_collection=chroma_client.get_or_create_collection("documents"))
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    
    index = VectorStoreIndex.from_documents(
        llama_docs, storage_context=storage_context
    )
    
    index.storage_context.persist(persist_dir=str(persist_dir))
    
    # 6. G√©n√©ration du r√©sum√© global
    synth = get_response_synthesizer()
    summary_parts = []
    for doc_info in documents_info:
        if doc_info.analysis:
            summary_parts.append(f"**{doc_info.type.value}** : {str(doc_info.analysis)}")
    
    global_summary = synth.get_response("", summary_parts) if summary_parts else "Aucune analyse disponible"
    
    # 7. Sauvegarde des analyses
    with open(persist_dir / "analyses.json", "w", encoding="utf-8") as f:
        json.dump([{
            "name": doc.name,
            "type": doc.type.value,
            "analysis": doc.analysis if doc.analysis else {}
        } for doc in documents_info], f, indent=2, ensure_ascii=False)
    
    with open(persist_dir / "global_summary.txt", "w", encoding="utf-8") as f:
        f.write(str(global_summary))
    
    # 8. G√©n√©ration de synth√®ses crois√©es et recommandations
    cross_analysis = generate_cross_analysis(documents_info, analyzer)
    
    # 9. Sauvegarde de l'analyse crois√©e
    with open(persist_dir / "cross_analysis.json", "w", encoding="utf-8") as f:
        json.dump(cross_analysis, f, indent=2, ensure_ascii=False)
    
    # 10. G√©n√©ration et sauvegarde de la m√©moire technique
    memory_generator = TechnicalMemoryGenerator()
    technical_memory = memory_generator.generate_technical_memory(cross_analysis)
    
    with open(persist_dir / "technical_memory.json", "w", encoding="utf-8") as f:
        json.dump(technical_memory, f, indent=2, ensure_ascii=False)
    
    return index, str(global_summary), token_handler.total_llm_token_count, documents_info, cross_analysis, technical_memory

def load_advanced_index(run_id: str):
    """Charge un index existant avec ses analyses."""
    persist_dir = VECTOR_DIR / run_id
    if not persist_dir.exists():
        return None, None
    
    # Chargement de l'index
    import chromadb
    chroma_client = chromadb.PersistentClient(path=str(persist_dir))
    vector_store = ChromaVectorStore(chroma_collection=chroma_client.get_or_create_collection("documents"))
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    index = VectorStoreIndex.from_vector_store(vector_store, storage_context)
    
    # Chargement des analyses
    analyses_file = persist_dir / "analyses.json"
    analyses = []
    if analyses_file.exists():
        with open(analyses_file, "r", encoding="utf-8") as f:
            analyses = json.load(f)
    
    # D√©s√©rialiser les analyses JSON dans les m√©tadonn√©es
    for analysis in analyses:
        if analysis.get('analysis') and isinstance(analysis['analysis'], str):
            try:
                analysis['analysis'] = json.loads(analysis['analysis'])
            except json.JSONDecodeError:
                analysis['analysis'] = {}
    
    return index, analyses

def display_analysis_section(section_name, section_content):
    """Affiche une section d'analyse de mani√®re format√©e."""
    st.markdown(f"### {section_name}")
    
    if isinstance(section_content, dict):
        # Afficher les sous-sections
        for subsection_name, subsection_content in section_content.items():
            if isinstance(subsection_content, dict):
                st.markdown(f"**{subsection_name}**")
                st.json(subsection_content)
            elif isinstance(subsection_content, list):
                st.markdown(f"**{subsection_name}**")
                for item in subsection_content:
                    st.markdown(f"- {item}")
            else:
                st.markdown(f"**{subsection_name}**: {subsection_content}")
    elif isinstance(section_content, list):
        for item in section_content:
            st.markdown(f"- {item}")
    else:
        st.markdown(f"{section_content}")
    
    st.markdown("---")

def generate_cross_analysis(documents_info: List[DocumentInfo], analyzer: DocumentAnalyzer) -> Dict[str, Any]:
    """G√©n√®re une analyse crois√©e et des recommandations bas√©es sur tous les documents."""
    
    # Collecter toutes les analyses
    all_analyses = {}
    for doc_info in documents_info:
        if doc_info.analysis:
            all_analyses[doc_info.type.value] = doc_info.analysis
    
    # G√©n√©rer des recommandations crois√©es
    recommendations_prompt = f"""
    Bas√© sur les analyses suivantes de documents d'appel d'offres, g√©n√®re des recommandations strat√©giques :
    
    ANALYSES :
    {json.dumps(all_analyses, indent=2, ensure_ascii=False)}
    
    G√©n√®re des recommandations dans les domaines suivants :
    
    1. STRAT√âGIE DE R√âPONSE
       - Points forts √† mettre en avant
       - Risques √† anticiper
       - Opportunit√©s √† saisir
       - Strat√©gie de prix
    
    2. PLANNING ET RESSOURCES
       - D√©lais critiques √† respecter
       - Ressources humaines n√©cessaires
       - Mat√©riaux et √©quipements
       - Sous-traitants potentiels
    
    3. GESTION DES RISQUES
       - Risques techniques identifi√©s
       - Risques administratifs
       - Risques financiers
       - Mesures de mitigation
    
    4. OPTIMISATIONS POSSIBLES
       - R√©duction des co√ªts
       - Am√©lioration des d√©lais
       - Optimisation des ressources
       - Innovations techniques
    
    5. SIMILITUDES AVEC EXP√âRIENCES PASS√âES
       - Chantiers similaires r√©alis√©s
       - Techniques √©prouv√©es
       - Retours d'exp√©rience
       - Am√©liorations possibles
    
    R√©ponds au format JSON structur√©.
    """
    
    try:
        response = analyzer.llm.complete(recommendations_prompt)
        recommendations = json.loads(response.text)
    except:
        recommendations = {"recommandations": "Analyse non disponible"}
    
    # G√©n√©rer une synth√®se des contraintes
    constraints_summary = {
        "contraintes_environnementales": {},
        "contraintes_logistiques": {},
        "contraintes_techniques": {},
        "contraintes_administratives": {}
    }
    
    for doc_type, analysis in all_analyses.items():
        if isinstance(analysis, dict):
            # Contraintes environnementales
            if "contraintes_environnementales" in analysis:
                constraints_summary["contraintes_environnementales"][doc_type] = analysis["contraintes_environnementales"]
            
            # Contraintes logistiques
            if "contraintes_logistiques" in analysis:
                constraints_summary["contraintes_logistiques"][doc_type] = analysis["contraintes_logistiques"]
            
            # Contraintes techniques (CCTP)
            if doc_type == "Cahier des Clauses Techniques Particuli√®res":
                constraints_summary["contraintes_techniques"] = analysis
            
            # Contraintes administratives (CCAP)
            if doc_type == "Cahier des Clauses Administratives Particuli√®res":
                constraints_summary["contraintes_administratives"] = analysis
    
    return {
        "recommandations_strategiques": recommendations,
        "synthese_contraintes": constraints_summary,
        "documents_analyses": len(documents_info),
        "types_documents": [doc.type.value for doc in documents_info]
    }

def generate_technical_memory_from_analysis(cross_analysis: Dict[str, Any], company_info: Dict[str, Any] = {}) -> Dict[str, Any]:
    """G√©n√®re une m√©moire technique bas√©e sur l'analyse crois√©e."""
    
    if not company_info:
        company_info = {
            "nom": "Entreprise de Restauration du Patrimoine",
            "siret": "12345678901234",
            "adresse": "123 Rue du Patrimoine, 75001 Paris",
            "telephone": "01 23 45 67 89",
            "email": "contact@restauration-patrimoine.fr",
            "experience": "15 ans d'exp√©rience en restauration de monuments historiques",
            "certifications": ["Qualibat 1511", "Monuments Historiques", "ISO 9001"]
        }
    
    memory_generator = TechnicalMemoryGenerator()
    technical_memory = memory_generator.generate_technical_memory(cross_analysis, company_info)
    
    return technical_memory

# --------------------------- Streamlit UI ---------------------

st.set_page_config("Analyse AO ‚Äì Multi-Agents", layout="wide")
st.title("üìë Analyse d'appels d'offres ‚Äì IA Multi-Agents")

# Session state init
if "run_id" not in st.session_state:
    st.session_state.run_id = None
if "index" not in st.session_state:
    st.session_state.index = None
if "chat_engine" not in st.session_state:
    st.session_state.chat_engine = None
if "history" not in st.session_state:
    st.session_state.history = []
if "analyses" not in st.session_state:
    st.session_state.analyses = []
if "cross_analysis" not in st.session_state:
    st.session_state.cross_analysis = None
if "technical_memory" not in st.session_state:
    st.session_state.technical_memory = None

# 1Ô∏è‚É£ Upload + ingestion avanc√©e
uploaded_files = st.file_uploader(
    "D√©pose tes fichiers d'appel d'offres (PDF, DOCX, XLSX‚Ä¶) :", 
    accept_multiple_files=True
)

if uploaded_files and st.button("üöÄ Lancer l'analyse multi-agents"):
    with st.spinner("Analyse en cours avec les agents sp√©cialis√©s‚Ä¶"):
        run_id = uuid.uuid4().hex[:8]
        index, summary, tokens, documents_info, cross_analysis, technical_memory = build_advanced_index(run_id, uploaded_files)
        
        st.session_state.run_id = run_id
        st.session_state.index = index
        st.session_state.chat_engine = index.as_chat_engine()
        st.session_state.analyses = [{
            "name": doc.name,
            "type": doc.type.value,
            "analysis": doc.analysis if doc.analysis else {}
        } for doc in documents_info]
        st.session_state.cross_analysis = cross_analysis
        st.session_state.technical_memory = technical_memory
        
        st.success(f"‚úÖ Analyse termin√©e ! Tokens LLM : {tokens}")
        
        # Affichage des r√©sultats par type de document
        st.subheader("üìä R√©sultats de l'analyse par document")
        
        # Ordre logique des documents
        document_order = [
            DocumentType.REGLEMENT,
            DocumentType.CCTP,
            DocumentType.CCAP,
            DocumentType.DPGF
        ]
        
        # Trier les documents selon l'ordre logique
        sorted_documents = []
        for doc_type in document_order:
            for doc_info in documents_info:
                if doc_info.type == doc_type:
                    sorted_documents.append(doc_info)
        
        # Afficher les documents dans l'ordre
        for doc_info in sorted_documents:
            with st.expander(f"üìÑ {doc_info.name} ({doc_info.type.value})"):
                if doc_info.analysis:
                    # Formater proprement l'analyse
                    if isinstance(doc_info.analysis, dict):
                        # Afficher chaque section de l'analyse s√©par√©ment
                        for section_name, section_content in doc_info.analysis.items():
                            display_analysis_section(section_name, section_content)
                    else:
                        st.json(doc_info.analysis)
                else:
                    st.info("Document trait√© mais pas d'analyse sp√©cialis√©e disponible")
        
        st.session_state.history.append({"role": "assistant", "content": summary})
        
        # Affichage des analyses crois√©es
        if cross_analysis:
            st.subheader("üéØ Recommandations strat√©giques")
            with st.expander("üìä Analyse crois√©e et recommandations"):
                recommendations = cross_analysis.get("recommandations_strategiques", {})
                if isinstance(recommendations, dict):
                    for section_name, section_content in recommendations.items():
                        display_analysis_section(section_name, section_content)
                else:
                    st.json(recommendations)
            
            st.subheader("üîç Synth√®se des contraintes")
            col1, col2 = st.columns(2)
            
            with col1:
                with st.expander("üå± Contraintes environnementales"):
                    st.json(cross_analysis["synthese_contraintes"]["contraintes_environnementales"])
                
                with st.expander("üöö Contraintes logistiques"):
                    st.json(cross_analysis["synthese_contraintes"]["contraintes_logistiques"])
            
            with col2:
                with st.expander("üîß Contraintes techniques"):
                    st.json(cross_analysis["synthese_contraintes"]["contraintes_techniques"])
                
                with st.expander("üìã Contraintes administratives"):
                    st.json(cross_analysis["synthese_contraintes"]["contraintes_administratives"])
        
        st.write("**R√©sum√© global :**")
        st.write(summary)
        
        # Phase 3 : G√©n√©ration de m√©moire technique
        st.subheader("üìã Phase 3 - G√©n√©ration de M√©moire Technique")
        
        # Configuration de l'entreprise
        with st.expander("üè¢ Configuration de l'entreprise"):
            col1, col2 = st.columns(2)
            
            with col1:
                company_name = st.text_input("Nom de l'entreprise", "Entreprise de Restauration du Patrimoine")
                company_siret = st.text_input("SIRET", "12345678901234")
                company_address = st.text_input("Adresse", "123 Rue du Patrimoine, 75001 Paris")
                company_phone = st.text_input("T√©l√©phone", "01 23 45 67 89")
            
            with col2:
                company_email = st.text_input("Email", "contact@restauration-patrimoine.fr")
                company_experience = st.text_input("Exp√©rience", "15 ans d'exp√©rience en restauration de monuments historiques")
                company_certifications = st.text_area("Certifications", "Qualibat 1511\nMonuments Historiques\nISO 9001")
        
        # Bouton de g√©n√©ration de m√©moire technique
        if st.button("üìÑ G√©n√©rer la m√©moire technique"):
            with st.spinner("G√©n√©ration de la m√©moire technique en cours..."):
                company_info = {
                    "nom": company_name,
                    "siret": company_siret,
                    "adresse": company_address,
                    "telephone": company_phone,
                    "email": company_email,
                    "experience": company_experience,
                    "certifications": company_certifications.split('\n') if company_certifications else []
                }
                
                technical_memory = generate_technical_memory_from_analysis(cross_analysis, company_info)
                st.session_state.technical_memory = technical_memory
                
                st.success("‚úÖ M√©moire technique g√©n√©r√©e avec succ√®s !")
                
                # Affichage de la m√©moire technique
                st.subheader("üìã M√©moire Technique G√©n√©r√©e")
                
                # R√©sum√© ex√©cutif
                memory_generator = TechnicalMemoryGenerator()
                summary = memory_generator.generate_memory_summary(technical_memory)
                
                with st.expander("üìä R√©sum√© ex√©cutif"):
                    st.markdown(summary)
                
                # Sections d√©taill√©es
                for section_name, section_content in technical_memory.get("sections", {}).items():
                    section_title = section_name.replace("_", " ").title()
                    with st.expander(f"üìÑ {section_title}"):
                        st.markdown(section_content)
                
                # Export Markdown
                markdown_content = memory_generator.export_memory_to_markdown(technical_memory)
                
                st.download_button(
                    label="üì• T√©l√©charger la m√©moire technique (Markdown)",
                    data=markdown_content,
                    file_name=f"memoire_technique_{st.session_state.run_id}.md",
                    mime="text/markdown"
                )

# 2Ô∏è‚É£ Chargement d'une session pr√©c√©dente
with st.sidebar:
    st.header("Sessions pr√©c√©dentes")
    runs = [p.name for p in VECTOR_DIR.iterdir() if p.is_dir()]
    sel = st.selectbox("R√©-ouvrir un run :", ["-"] + runs)
    if sel != "-" and sel != st.session_state.get("run_id"):
        index, analyses = load_advanced_index(sel)
        if index:
            st.session_state.index = index
            st.session_state.chat_engine = index.as_chat_engine()
            st.session_state.run_id = sel
            st.session_state.analyses = analyses
            st.session_state.history.append({
                "role": "assistant",
                "content": f"Session {sel} recharg√©e avec {len(analyses) if analyses else 0} documents analys√©s. Pose ta question !"
            })
            
            # Charger la m√©moire technique si elle existe
            persist_dir = VECTOR_DIR / sel
            memory_file = persist_dir / "technical_memory.json"
            if memory_file.exists():
                with open(memory_file, "r", encoding="utf-8") as f:
                    st.session_state.technical_memory = json.load(f)

# 3Ô∏è‚É£ Affichage des analyses en cours
if st.session_state.analyses:
    st.subheader("üìã Documents analys√©s")
    for analysis in st.session_state.analyses:
        with st.expander(f"üìÑ {analysis['name']} ({analysis['type']})"):
            if analysis.get('analysis'):
                st.json(analysis['analysis'])
            else:
                st.info("Aucune analyse disponible")

# 4Ô∏è‚É£ Affichage de la m√©moire technique existante
if st.session_state.technical_memory:
    st.subheader("üìã M√©moire Technique G√©n√©r√©e")
    
    # R√©sum√© ex√©cutif
    memory_generator = TechnicalMemoryGenerator()
    summary = memory_generator.generate_memory_summary(st.session_state.technical_memory)
    
    with st.expander("üìä R√©sum√© ex√©cutif"):
        st.markdown(summary)
    
    # Sections d√©taill√©es
    for section_name, section_content in st.session_state.technical_memory.get("sections", {}).items():
        section_title = section_name.replace("_", " ").title()
        with st.expander(f"üìÑ {section_title}"):
            st.markdown(section_content)
    
    # Export Markdown
    markdown_content = memory_generator.export_memory_to_markdown(st.session_state.technical_memory)
    
    st.download_button(
        label="üì• T√©l√©charger la m√©moire technique (Markdown)",
        data=markdown_content,
        file_name=f"memoire_technique_{st.session_state.run_id}.md",
        mime="text/markdown"
    )

# 4Ô∏è‚É£ Zone de chat am√©lior√©e
if st.session_state.chat_engine:
    st.subheader("üí¨ Chat avec l'agent d'analyse")
    
    for h in st.session_state.history:
        avatar = "üßë‚Äçüíº" if h["role"] == "user" else "ü§ñ"
        st.chat_message(avatar).markdown(h["content"])

    if q := st.chat_input("Pose ta question sur l'appel d'offres‚Ä¶"):
        st.session_state.history.append({"role": "user", "content": q})
        st.chat_message("üßë‚Äçüíº").markdown(q)
        with st.chat_message("ü§ñ"):
            try:
                answer = st.session_state.chat_engine.chat(q)
                st.markdown(answer)
                st.session_state.history.append({"role": "assistant", "content": str(answer)})
            except Exception as e:
                error_msg = f"Erreur lors de la g√©n√©ration de la r√©ponse : {str(e)}"
                st.error(error_msg)
                st.session_state.history.append({"role": "assistant", "content": error_msg})
else:
    st.info("‚û°Ô∏è  Ajoute des fichiers puis lance l'analyse multi-agents pour activer le chat intelligent.")
